{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0877a606",
   "metadata": {},
   "source": [
    "# install simple salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ed0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simple_salesforce\n",
    "# pip install tabpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240e05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /Users/jungmeepark/opt/anaconda3/lib/python3.9/site-packages (2.8.4)\n",
      "Requirement already satisfied: numpy in /Users/jungmeepark/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\n",
      "Requirement already satisfied: pandas in /Users/jungmeepark/opt/anaconda3/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jungmeepark/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jungmeepark/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/jungmeepark/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jungmeepark/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Prerequisites\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install --user networkx\n",
    "!{sys.executable} -m pip install --user numpy\n",
    "!{sys.executable} -m pip install --user pandas\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import csv\n",
    "import glob\n",
    "import scipy.sparse\n",
    "\n",
    "from simple_salesforce import Salesforce\n",
    "from io import StringIO\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sf = Salesforce(username='',password='', security_token='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b30354",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "sf_instance = 'https://ua-trellis.lightning.force.com/' #Your Salesforce Instance URL\n",
    "reportId = '00O6R000008QxpyUAC' # add report id\n",
    "export = '?isdtp=p1&export=1&enc=UTF-8&xf=csv'\n",
    "sfUrl = sf_instance + reportId + export\n",
    "response = requests.get(sfUrl, headers=sf.headers, cookies={'sid': sf.session_id})\n",
    "download_report = response.content.decode('utf-8')\n",
    "df1 = pd.read_csv(StringIO(download_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9002358",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834baaef",
   "metadata": {},
   "source": [
    "directory = '/Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/'\n",
    "\n",
    "for file_name in glob.glob(directory+'*.csv'):\n",
    "    x = np.genfromtxt(file_name,delimiter=',')[:,2]\n",
    "    # do your calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df214f5f",
   "metadata": {},
   "source": [
    "# Define the directory path\n",
    "as /Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce\n",
    "directory = '/Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter out only the CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file and read it\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Now you can work with the DataFrame 'df' for each CSV file\n",
    "    print(\"Loaded:\", file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69307eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wr/p82k0vm11j17r80bp7wf3swc0000gs/T/ipykernel_17107/2963542495.py:4: DtypeWarning: Columns (4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cases_report_SF = pd.read_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/POC_Cases_May22_2024.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read in Source File - NB this must match the schema requirements\n",
    "# read in data\n",
    "# /Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce\n",
    "cases_report_SF = pd.read_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/POC_Cases_May22_2024.csv')\n",
    "CodeType = 'latin1' # https://docs.python.org/3/library/codecs.html#standard-encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12de2349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts:\n",
      " Service    198679\n",
      "Note       139320\n",
      "Name: Case Record Type, dtype: int64\n",
      "Number of unique Case Record Types: 2\n"
     ]
    }
   ],
   "source": [
    "value_counts = cases_report_SF['Case Record Type'].value_counts()\n",
    "print(\"Value Counts:\\n\", value_counts)\n",
    "\n",
    "# Count the number of unique values\n",
    "unique_count = cases_report_SF['Case Record Type'].nunique()\n",
    "print(\"Number of unique Case Record Types:\", unique_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0fe62de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject                          object\n",
       "Date/Time Opened         datetime64[ns]\n",
       "Open                              int64\n",
       "Closed                            int64\n",
       "Department                       object\n",
       "Contact: Email                   object\n",
       "Emplid                           object\n",
       "Case Last Modified By            object\n",
       "Contact ID                       object\n",
       "Age (Hours)                       int64\n",
       "Case Record Type                 object\n",
       "Date Opened              datetime64[ns]\n",
       "today                    datetime64[ns]\n",
       "days_since                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatypes = cases_report_SF.dtypes \n",
    "datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc826301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cases_report_SF = cases_report_SF[['Department', 'Case Last Modified By','Contact: Email', 'Emplid', 'Case Record Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17735b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337999, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows where case record type and Case last modified by is NA or empty\n",
    "#cases_report_SF = cases_report_SF.dropna(subset=['Case Record Type', 'Department'])\n",
    "cases_report_SF = cases_report_SF.dropna(subset=['Case Record Type', 'Case Last Modified By'])\n",
    "cases_report_SF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1027f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_report_SF = cases_report_SF[\n",
    "    (~cases_report_SF['Case Record Type'].isna()) | (cases_report_SF['Case Record Type'] != \"\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2e7926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Appointment Date' column to datetime\n",
    "cases_report_SF['Date/Time Opened'] = pd.to_datetime(cases_report_SF['Date/Time Opened'])\n",
    "\n",
    "# Convert the \"Open/Close Date\" column to datetime objects\n",
    "cases_report_SF['Date/Time Opened'] = pd.to_datetime(cases_report_SF['Date/Time Opened'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Extract the date part\n",
    "cases_report_SF['Date Opened'] = cases_report_SF['Date/Time Opened'].dt.date\n",
    "\n",
    "cases_report_SF['Date Opened']= pd.to_datetime(cases_report_SF['Date Opened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d661205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate today's date\n",
    "today = pd.to_datetime('today').normalize()\n",
    "cases_report_SF['today'] = today\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04831b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate days since 'openDate'\n",
    "cases_report_SF['days_since'] = (cases_report_SF['today'] - cases_report_SF['Date Opened']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b80c4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim down the cases to make the merge possible\n",
    "cases_report_SF = cases_report_SF[\n",
    "    (~cases_report_SF['Case Record Type'].isna()) | (cases_report_SF['Case Record Type'] != \"\")\n",
    "]\n",
    "\n",
    "cases_report_SF = cases_report_SF[\n",
    "    (~cases_report_SF['Contact: Email'].isna()) | (cases_report_SF['Contact: Email'] != \"\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc1ae702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts:\n",
      " Service    198679\n",
      "Note       139320\n",
      "Name: Case Record Type, dtype: int64\n",
      "Number of unique Case Record Types: 2\n"
     ]
    }
   ],
   "source": [
    "value_counts = cases_report_SF['Case Record Type'].value_counts()\n",
    "print(\"Value Counts:\\n\", value_counts)\n",
    "\n",
    "# Count the number of unique values\n",
    "unique_count = cases_report_SF['Case Record Type'].nunique()\n",
    "print(\"Number of unique Case Record Types:\", unique_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a52aca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an index column\n",
    "\n",
    "cases_report_SF['index'] = range(1, len(cases_report_SF) + 1)\n",
    "#filtered_df['index'] = filtered_df.index\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bfda856",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_report_SF = cases_report_SF.rename(columns={'Contact: Email': 'Student Email', 'Case Last Modified By': 'Advisor Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0476093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a source column\n",
    "cases_report_SF['Source'] = cases_report_SF.groupby(['Emplid']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab1ee3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_report_SF['Target'] = cases_report_SF.groupby(['Department']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e33a8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_report_SF['Source'] = cases_report_SF['Source'].map(str)\n",
    "cases_report_SF['Target'] = cases_report_SF['Target'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb7cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add directions to d3\n",
    "cases_report_SF['Direction'] = cases_report_SF['Source'] + ' -> ' + cases_report_SF['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d919b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'NAME' and check if any row within the group has a non-null 'DEPARTMENT'\n",
    "grouped = cases_report_SF.groupby('Advisor Name')['Department'].transform('first')\n",
    "# Impute the 'DEPARTMENT' value within each group\n",
    "cases_report_SF['Department'] = cases_report_SF['Department'].fillna(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a40d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLLOWING KNIPPENBERG\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "cases_report_SF.to_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/generated_from_knipp/py-cases_report_SF_May22_2024.csv', index=False)  # Set index=False to exclude the index from the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee0401cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_SrcTgt = np.array(cases_report_SF[['Source','Target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aadd4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of contacts between each student and department\n",
    "contact_counts = cases_report_SF.groupby(['Source', 'Target']).size().reset_index(name='ContactCount')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9bf70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MultiDiGraph\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "# Add edges with the 'ContactCount' as weight\n",
    "for _, row in contact_counts.iterrows():\n",
    "    student = row['Source']\n",
    "    department = row['Target']\n",
    "    contact_count = row['ContactCount']\n",
    "    G.add_edge(student, department, weight=contact_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the edges with weights\n",
    "for u, v, data in G.edges(data=True):\n",
    "    print(f\"Student: {u}, Department: {v}, Contact Count: {data['weight']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b59b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=3000, font_size=15, font_weight='bold', arrowsize=20)\n",
    "\n",
    "# Draw edge labels with the contact count\n",
    "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n",
    "plt.title('Student-Department Contact Graph')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce653a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Network Graph Coordinates...\n",
    "# G = nx.MultiDiGraph()\n",
    "G.add_edges_from(arr_SrcTgt)\n",
    "dict_Coords = nx.spring_layout(G) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph Coordinates File...\n",
    "df_Raw_Coords = DataFrame(dict_Coords)\n",
    "df_Raw_Coords = df_Raw_Coords.T\n",
    "df_Raw_Coords.columns = ['X','Y']\n",
    "df_Raw_Coords.to_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/generated_from_knipp/CoordsFile_merged_May21_2024.csv', \n",
    "                     index_label='NodeName')\n",
    "#print(df_Raw_Coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bridge File... \n",
    "# Tableau Code: IF [Src-Tgt]/2 = ROUND([Src-Tgt]/2) THEN 'Source' ELSE 'Target' END\n",
    "arr_SrcTgt2 = arr_SrcTgt.reshape(1,(len(arr_SrcTgt)*2)) \n",
    "arr_SrcTgt2 = arr_SrcTgt2.reshape(-1) \n",
    "df_SrcTgt = DataFrame(arr_SrcTgt2,columns=['NodeName']) \n",
    "arr_Index = []\n",
    "for i in range(1,(len(arr_SrcTgt)+1)):\n",
    "    arr_Index.append(i)\n",
    "    arr_Index.append(i)\n",
    "df_SrcTgt['c_Index'] = arr_Index \n",
    "\n",
    "df_SrcTgt.to_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/generated_from_knipp/BridgeFile_merged_May21_2024.csv',\n",
    "                 index_label='Src-Tgt')\n",
    "#print(df_ScrTgt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(dict_Coords)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138708ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.draw(Q, pos=nx.spring_layout(Q));\n",
    "nx.draw(Q, pos=nx.spring_layout(Q), with_labels=True, node_size=100, node_color=\"skyblue\", edge_color=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8618c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness centrality\n",
    "plt.hist(nx.centrality.closeness_centrality(Q).values());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.diameter(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.cluster.average_clustering(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44168ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree distribution (a histogram of how many edges each node has)\n",
    "\n",
    "plt.hist([v for k,v in nx.degree(Q)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1825cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degrees = [v for k, v in nx.degree(Q)]\n",
    "\n",
    "# Calculate the range of your data\n",
    "min_degree = min(degrees)\n",
    "max_degree = max(degrees)\n",
    "\n",
    "# Calculate the number of bins based on increments of 10\n",
    "num_bins = int((max_degree - min_degree) / 10) + 1\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(degrees, bins=num_bins)\n",
    "plt.xlim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58073057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Run Completed Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [v for k, v in nx.degree(Q)]\n",
    "\n",
    "# Calculate the range of your data\n",
    "min_degree = min(degrees)\n",
    "max_degree = max(degrees)  # Truncate the maximum degree to 600\n",
    "\n",
    "# Calculate the number of bins based on increments of 5\n",
    "num_bins = int((max_degree - min_degree) / 5) + 1\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(degrees, bins=num_bins)\n",
    "plt.xlim(0, 200)  # Set the limit of x-axis from 0 to 600\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32145e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
