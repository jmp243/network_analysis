{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0877a606",
   "metadata": {},
   "source": [
    "# install simple salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ed0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simple_salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prerequisites\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install --user networkx\n",
    "!{sys.executable} -m pip install --user numpy\n",
    "!{sys.executable} -m pip install --user pandas\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import csv\n",
    "import glob\n",
    "import scipy.sparse\n",
    "\n",
    "from simple_salesforce import Salesforce\n",
    "from io import StringIO\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sf = Salesforce(username='',password='', security_token='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b30354",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "sf_instance = 'https://ua-trellis.lightning.force.com/' #Your Salesforce Instance URL\n",
    "reportId = '00O6R000008QxpyUAC' # add report id\n",
    "export = '?isdtp=p1&export=1&enc=UTF-8&xf=csv'\n",
    "sfUrl = sf_instance + reportId + export\n",
    "response = requests.get(sfUrl, headers=sf.headers, cookies={'sid': sf.session_id})\n",
    "download_report = response.content.decode('utf-8')\n",
    "df1 = pd.read_csv(StringIO(download_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9002358",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834baaef",
   "metadata": {},
   "source": [
    "directory = '/Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/'\n",
    "\n",
    "for file_name in glob.glob(directory+'*.csv'):\n",
    "    x = np.genfromtxt(file_name,delimiter=',')[:,2]\n",
    "    # do your calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df214f5f",
   "metadata": {},
   "source": [
    "# Define the directory path\n",
    "as /Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce\n",
    "directory = '/Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter out only the CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file and read it\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Now you can work with the DataFrame 'df' for each CSV file\n",
    "    print(\"Loaded:\", file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69307eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Source File - NB this must match the schema requirements\n",
    "# read in data\n",
    "# /Users/jungmeepark/Documents/Trellis/Network_Analysis_Tableau/data/salesforce\n",
    "cases_report_SF = pd.read_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/POC_Network_Analysis_Cases.csv')\n",
    "initial_report_SF = pd.read_csv(\"~/Documents/Trellis/Network_Analysis_Tableau/data/salesforce/practice_appointments_POC.csv\")\n",
    "#CodeType = 'latin1' # https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "print(initial_report_SF.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cases_report_SF.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(initial_report_SF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17735b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where case record type and department is NA or empty\n",
    "cases_report_SF = cases_report_SF.dropna(subset=['Case Record Type', 'Department'])\n",
    "cases_report_SF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where `Case ID` or `Contact EmplID` is NA or empty\n",
    "initial_report_SF = initial_report_SF.dropna(subset=['Case Number', 'Case ID', 'Contact EmplID'])\n",
    "initial_report_SF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim down the cases to make the merge possible\n",
    "initial_report_SF = initial_report_SF[\n",
    "    (~initial_report_SF['Case ID'].isna()) | (initial_report_SF['Case ID'] != \"\")\n",
    "]\n",
    "\n",
    "initial_report_SF = initial_report_SF[\n",
    "    (~initial_report_SF['Contact EmplID'].isna()) | (initial_report_SF['Contact EmplID'] != \"\")\n",
    "]\n",
    "\n",
    "cases_report_SF = cases_report_SF[\n",
    "    (~cases_report_SF['Case Record Type'].isna()) | (cases_report_SF['Case Record Type'] != \"\")\n",
    "]\n",
    "\n",
    "cases_report_SF = cases_report_SF[\n",
    "    (~cases_report_SF['Department'].isna()) | (cases_report_SF['Department'] != \"\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "filtered_df = pd.merge(cases_report_SF, initial_report_SF, how='left', left_on='Emplid', right_on='Contact EmplID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0461243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where `Case ID` or `Contact EmplID` is NA or empty\n",
    "#filtered_df = merged_df.dropna(subset=['Case Number', 'Case ID', 'Contact EmplID'])\n",
    "#initial_report_SF = initial_report_SF[(~initial_report_SF['Case ID'].isna()) | (initial_report_SF['Case ID'] != \"\")]\n",
    "#initial_report_SF = initial_report_SF[(~initial_report_SF['Contact EmplID'].isna()) | (initial_report_SF['Contact EmplID'] != \"\")]\n",
    "#print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ae702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Appointment Date' column to datetime\n",
    "filtered_df['AppointmentDate'] = pd.to_datetime(filtered_df['Appointment Date'])\n",
    "\n",
    "# Calculate today's date\n",
    "today = pd.to_datetime('today').normalize()\n",
    "filtered_df['today'] = today\n",
    "\n",
    "# Calculate days since 'AppointmentDate'\n",
    "filtered_df['days_since'] = (filtered_df['today'] - filtered_df['AppointmentDate']).dt.days\n",
    "\n",
    "# filter dates to 2024\n",
    "#filtered_df[(filtered_df['date']>datetime.date(2024,1,1)) & (filtered_df['date']<datetime.date(2024,5,5))]\n",
    "filtered_df = filtered_df[(filtered_df['AppointmentDate'] > \"2024-01-01\") & (filtered_df['AppointmentDate'] < \"2024-07-01\")]\n",
    "# Display the updated DataFrame\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763288e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new emplID's\n",
    "# Extract unique IDs\n",
    "unique_ids = filtered_df['Contact EmplID'].unique()\n",
    "\n",
    "# Generate new IDs (random IDs)\n",
    "np.random.seed(53013)  # for reproducibility\n",
    "new_ids = np.random.randint(1000, 9999, len(unique_ids))\n",
    "\n",
    "# Create a dictionary to map old IDs to new IDs\n",
    "id_mapping = dict(zip(unique_ids, new_ids))\n",
    "\n",
    "id_mapping\n",
    "#filtered_df_newID=filtered_df.append(id_mapping,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de39194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df['Contact EmplID'].map(id_mapping)  \n",
    "filtered_df['New_ID'] = filtered_df['Contact EmplID'].map(id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variable names (column names) of the DataFrame\n",
    "variable_names = filtered_df.columns\n",
    "\n",
    "print(variable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168918e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column to extract the names\n",
    "# Extract just the names\n",
    "filtered_df['Student Name'] = filtered_df['Appointment Name'].str.split(' - ', expand=True)[1]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49406f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variable names (column names) of the DataFrame\n",
    "variable_names = filtered_df.columns\n",
    "\n",
    "print(variable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52aca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an index column\n",
    "\n",
    "filtered_df['index'] = range(1, len(filtered_df) + 1)\n",
    "#filtered_df['index'] = filtered_df.index\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0476093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a source column\n",
    "filtered_df['Source'] = filtered_df.groupby(['Advisor Name']).ngroup()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfda856",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.rename(columns={'Owner: Owner ID': 'owner_id', 'New_ID': 'Target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f68c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Source'] = filtered_df['Source'].map(str)\n",
    "filtered_df['Target'] = filtered_df['Target'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add directions to d3\n",
    "filtered_df['Direction'] = filtered_df['Source'] + ' -> ' + filtered_df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'NAME' and check if any row within the group has a non-null 'DEPARTMENT'\n",
    "grouped = filtered_df.groupby('Advisor Name')['Department'].transform('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aff70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the 'DEPARTMENT' value within each group\n",
    "filtered_df['Department'] = filtered_df['Department'].fillna(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLLOWING KNIPPENBERG\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "\n",
    "filtered_df.to_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/generated_from_knipp/py-filtered_merged_df.csv', index=False)  # Set index=False to exclude the index from the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57849b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_df = filtered_df.sample(n=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0401cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_SrcTgt = np.array(filtered_df[['Source','Target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce653a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Network Graph Coordinates...\n",
    "Q = nx.MultiDiGraph()\n",
    "Q.add_edges_from(arr_SrcTgt)\n",
    "dict_Coords = nx.spring_layout(Q) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph Coordinates File...\n",
    "df_Raw_Coords = DataFrame(dict_Coords)\n",
    "df_Raw_Coords = df_Raw_Coords.T\n",
    "df_Raw_Coords.columns = ['X','Y']\n",
    "df_Raw_Coords.to_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/generated_from_knipp/CoordsFile_merged.csv', \n",
    "                     index_label='NodeName')\n",
    "#print(df_Raw_Coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bridge File... \n",
    "# Tableau Code: IF [Src-Tgt]/2 = ROUND([Src-Tgt]/2) THEN 'Source' ELSE 'Target' END\n",
    "arr_SrcTgt2 = arr_SrcTgt.reshape(1,(len(arr_SrcTgt)*2)) \n",
    "arr_SrcTgt2 = arr_SrcTgt2.reshape(-1) \n",
    "df_SrcTgt = DataFrame(arr_SrcTgt2,columns=['NodeName']) \n",
    "arr_Index = []\n",
    "for i in range(1,(len(arr_SrcTgt)+1)):\n",
    "    arr_Index.append(i)\n",
    "    arr_Index.append(i)\n",
    "df_SrcTgt['c_Index'] = arr_Index \n",
    "\n",
    "df_SrcTgt.to_csv('~/Documents/Trellis/Network_Analysis_Tableau/data/generated_from_knipp/BridgeFile_merged.csv',\n",
    "                 index_label='Src-Tgt')\n",
    "#print(df_ScrTgt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(dict_Coords)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138708ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.draw(Q, pos=nx.spring_layout(Q));\n",
    "nx.draw(Q, pos=nx.spring_layout(Q), with_labels=True, node_size=100, node_color=\"skyblue\", edge_color=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8618c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# betweenness centrality\n",
    "plt.hist(nx.centrality.closeness_centrality(Q).values());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.diameter(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.cluster.average_clustering(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44168ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree distribution (a histogram of how many edges each node has)\n",
    "\n",
    "plt.hist([v for k,v in nx.degree(Q)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1825cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degrees = [v for k, v in nx.degree(Q)]\n",
    "\n",
    "# Calculate the range of your data\n",
    "min_degree = min(degrees)\n",
    "max_degree = max(degrees)\n",
    "\n",
    "# Calculate the number of bins based on increments of 10\n",
    "num_bins = int((max_degree - min_degree) / 10) + 1\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(degrees, bins=num_bins)\n",
    "plt.xlim(0, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58073057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Run Completed Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [v for k, v in nx.degree(Q)]\n",
    "\n",
    "# Calculate the range of your data\n",
    "min_degree = min(degrees)\n",
    "max_degree = max(degrees)  # Truncate the maximum degree to 600\n",
    "\n",
    "# Calculate the number of bins based on increments of 5\n",
    "num_bins = int((max_degree - min_degree) / 5) + 1\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(degrees, bins=num_bins)\n",
    "plt.xlim(0, 200)  # Set the limit of x-axis from 0 to 600\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32145e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
